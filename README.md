# Resume Screening AI

An intelligent resume screening system powered by Machine Learning and Natural Language Processing. Automatically analyze, score, and match resumes against job requirements with advanced ML ensemble models.

## ğŸš€ Features

### Core Capabilities
- **Smart Resume Analysis**: Advanced NLP-based parsing and analysis
- **Job Matching**: AI-powered resume-to-job matching with intelligent scoring
- **Ensemble ML Models**: XGBoost, LightGBM, Random Forest, Gradient Boosting
- **Skill Extraction**: Fuzzy matching for skills, certifications, and experience levels
- **Quality Scoring**: Comprehensive resume quality assessment and feedback
- **Batch Processing**: Process 100+ resumes per minute efficiently
- **Real-time Prediction**: Sub-100ms ML inference per resume
- **Database Integration**: MongoDB for scalability + SQLite fallback

### User Interface
- **Web Dashboard**: Clean, responsive interface for resume analysis
- **Bulk Upload**: Process multiple resumes simultaneously
- **Result Export**: CSV export for integration with HR systems
- **Feedback Loop**: Tag and collect training data for continuous improvement

## ğŸ“‹ Prerequisites

- **Python**: 3.8 or higher
- **Database**: MongoDB 4.0+ (optional, SQLite fallback available)
- **System**: 4GB RAM minimum recommended
- **OS**: Windows, Linux, or macOS

## ğŸ”§ Installation

### Step 1: Create Virtual Environment
```bash
python -m venv venv

# Activate (Windows)
venv\Scripts\activate

# Activate (Linux/Mac)
source venv/bin/activate
```

### Step 2: Install Dependencies
```bash
pip install -r requirements.txt
```

For development/testing:
```bash
pip install -r requirements-dev.txt
```

### Step 3: Configure Environment (Optional)
```bash
# Database configuration (app uses SQLite by default)
# To use MongoDB, update config.py or set MONGODB_URI environment variable

# For development mode:
set FLASK_ENV=development
set FLASK_DEBUG=1
```

### Step 4: Run the Application
```bash
# Main web application
python Dynamic_Resume_Screener/app.py

# Opens at: http://localhost:5000
```

## ğŸ¯ Quick Start

### 1. Upload & Analyze Resume
1. Navigate to `http://localhost:5000`
2. Upload a resume (PDF, DOCX, or TXT)
3. Optionally provide a job description
4. View instant analysis and ML scoring

### 2. Bulk Processing
```bash
python Dynamic_Resume_Screener/batch_resume_processor.py
```

### 3. Train Custom Model
```bash
# Step 1: Collect feedback (mark good/bad resumes)
python Dynamic_Resume_Screener/add_feedback_quick.py

# Step 2: Train model (requires 50+ samples)
python Dynamic_Resume_Screener/train_improved_model.py

# Step 3: Check results
python Dynamic_Resume_Screener/check_training_result.py
```

## ğŸ“ Project Structure

```
Resume_Screening_AI/
â”œâ”€â”€ Dynamic_Resume_Screener/    # Main application
â”‚   â”œâ”€â”€ app.py                  # Flask web app
â”‚   â”œâ”€â”€ ml_models_improved.py   # Ensemble ML models
â”‚   â”œâ”€â”€ training_pipeline_improved.py  # Model training
â”‚   â”œâ”€â”€ database.py             # Database interface
â”‚   â”œâ”€â”€ mongodb_database.py     # MongoDB implementation
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ batch_resume_processor.py  # Bulk processing
â”‚   â””â”€â”€ templates/              # HTML templates
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ results.html
â”‚       â””â”€â”€ ...
â”œâ”€â”€ app/                        # Package structure
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ mongodb.py          # MongoDB drivers
â”‚   â”‚   â””â”€â”€ sqlite.py           # SQLite drivers
â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”œâ”€â”€ models.py           # ML implementations
â”‚   â”‚   â””â”€â”€ training.py         # Training logic
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ scripts/                    # Utility scripts
â”‚   â”œâ”€â”€ data/                   # Data processing scripts
â”‚   â”œâ”€â”€ ml/                     # ML training scripts
â”‚   â””â”€â”€ setup/                  # Initialization
â”œâ”€â”€ tools/                      # Development tools
â”‚   â”œâ”€â”€ check_db_status.py
â”‚   â”œâ”€â”€ check_feedback_distribution.py
â”‚   â”œâ”€â”€ view_data.py
â”‚   â””â”€â”€ ...
â”œâ”€â”€ data/                       # Data storage
â”‚   â”œâ”€â”€ database/               # Database files
â”‚   â”œâ”€â”€ models/                 # Trained models
â”‚   â””â”€â”€ resumes/                # Sample resumes
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ requirements.txt            # Production dependencies
â”œâ”€â”€ requirements-dev.txt        # Development dependencies
â”œâ”€â”€ setup.py                    # Package configuration
â””â”€â”€ README.md                   # This file
```

## ğŸ§ª Testing

```bash
# Run all tests with coverage
pytest --cov=app tests/

# Run specific test module
pytest tests/test_analyzer.py -v

# Run with detailed output
pytest -vv --tb=short
```

## ğŸ“Š Training & Improvement

### Data Collection
```bash
# Add feedback for resumes (mark as good/bad/neutral)
python Dynamic_Resume_Screener/add_feedback_quick.py

# Bulk import feedback from CSV
python Dynamic_Resume_Screener/import_batch_results.py

# View feedback distribution
python tools/check_feedback_distribution.py
```

### Model Training
```bash
# Train improved ensemble model (requires 50+ labeled samples)
python Dynamic_Resume_Screener/train_improved_model.py

# Check training status and results
python Dynamic_Resume_Screener/check_training_result.py

# View model metadata and performance
tools/check_model_metadata.py
```

### Development Tools
```bash
# Check database connection status
python tools/check_db_status.py

# View all stored resumes and scores
python tools/view_data.py

# Show feedback statistics
python Dynamic_Resume_Screener/check_feedback_count.py

# Verify feedback distribution
python Dynamic_Resume_Screener/check_feedback_distribution.py
```

## ğŸ³ Docker Deployment

```bash
# Build and run with Docker Compose
docker-compose up -d

# View logs
docker-compose logs -f

# Stop services
docker-compose down
```

## ğŸ“š API Documentation

### Upload Resume
```
POST /upload
Content-Type: multipart/form-data

Parameters:
- resume: file (PDF/DOCX/TXT)
- job_description: string (optional)

Response: JSON with analysis results
```

### Export Results
```
GET /export?format=csv
Response: CSV file download
```

See [docs/API.md](docs/API.md) for complete API documentation.

## ğŸ› ï¸ Configuration

Edit `app/config.py` or use environment variables:

```python
# ML Configuration
MIN_TRAINING_SAMPLES = 50
CONFIDENCE_THRESHOLD = 0.7

# Database
MONGODB_URI = "mongodb://localhost:27017/"

# File Upload
MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB
```

## ğŸ“ˆ Performance

- **Analysis Speed**: ~2-5 seconds per resume
- **Batch Processing**: 100+ resumes/minute
- **ML Prediction**: <100ms per resume
- **Database**: Handles 10K+ resumes efficiently

## ğŸ”’ Security Notes

âš ï¸ **Important**: This is a development version. For production use:

1. Enable authentication (see docs/DEPLOYMENT.md)
2. Use HTTPS/SSL
3. Configure proper MongoDB security
4. Set strong SECRET_KEY
5. Enable rate limiting
6. Review GDPR compliance

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

## ğŸ‘¥ Authors

- **Raj Kadam** - Initial work

## ğŸ™ Acknowledgments

- Flask framework
- scikit-learn for ML
- MongoDB for database
- sentence-transformers for NLP

## ğŸ“ Support

For issues and questions:
- Create an issue on GitHub
- Email: [your-email]
- Documentation: [docs/](docs/)

## ğŸ—ºï¸ Roadmap

- [ ] User authentication system
- [ ] REST API with JWT
- [ ] Advanced ML models (BERT, transformers)
- [ ] Real-time resume ranking
- [ ] Email notifications
- [ ] Multi-language support
- [ ] Mobile app

## ğŸ“Š Current Status

**Version**: 1.0.0-dev  
**Status**: Development  
**Production Ready**: No (see production_readiness_assessment.md)

---

**Note**: This project is currently in development. See `production_readiness_assessment.md` for production deployment requirements.
